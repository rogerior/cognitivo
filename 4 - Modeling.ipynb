{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import tree, neighbors, ensemble, discriminant_analysis, neural_network\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type_Red</th>\n",
       "      <th>type_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>31.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99728</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.611</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.078</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.86</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.026</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.99184</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.3              0.48         0.32             2.1      0.062   \n",
       "1            7.7              0.41         0.76             1.8      0.611   \n",
       "2            7.9              0.35         0.46             3.6      0.078   \n",
       "3            8.5              0.19         0.48             1.1      0.026   \n",
       "4            9.1              0.28         0.46             9.0      0.114   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 31.0                  54.0  0.99728  3.30       0.65   \n",
       "1                  8.0                  45.0  0.99680  3.06       1.26   \n",
       "2                 15.0                  37.0  0.99730  3.35       0.86   \n",
       "3                 23.0                  58.0  0.99184  2.90       0.50   \n",
       "4                  3.0                   9.0  0.99901  3.18       0.60   \n",
       "\n",
       "   alcohol  quality  type_Red  type_White  \n",
       "0     10.0        7         1           0  \n",
       "1      9.4        5         1           0  \n",
       "2     12.8        8         1           0  \n",
       "3     10.5        6         0           1  \n",
       "4     10.9        6         1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_csv('dados/treino.csv', sep=';')\n",
    "\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar dados em atributos (X) e classe (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop('quality', axis=1)\n",
    "y = dados.quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista com todas as técnicas que serão utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tecnicas_regressao = [\n",
    "    ('RandomForestRegressor', sklearn.ensemble.forest.RandomForestRegressor()),\n",
    "    ('ExtraTreesRegressor', sklearn.ensemble.forest.ExtraTreesRegressor()),\n",
    "    ('BaggingRegressor', sklearn.ensemble.bagging.BaggingRegressor()),\n",
    "    ('GradientBoostingRegressor', sklearn.ensemble.gradient_boosting.GradientBoostingRegressor()),\n",
    "    ('AdaBoostRegressor', sklearn.ensemble.weight_boosting.AdaBoostRegressor()),\n",
    "    ('HuberRegressor', sklearn.linear_model.huber.HuberRegressor()),\n",
    "    ('LinearRegression', sklearn.linear_model.base.LinearRegression()),\n",
    "    ('PassiveAggressiveRegressor', sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor()),\n",
    "    ('SGDRegressor', sklearn.linear_model.stochastic_gradient.SGDRegressor()),\n",
    "    ('TheilSenRegressor', sklearn.linear_model.theil_sen.TheilSenRegressor()),\n",
    "    ('KNeighborsRegressor', sklearn.neighbors.regression.KNeighborsRegressor()),\n",
    "    ('RadiusNeighborsRegressor', sklearn.neighbors.regression.RadiusNeighborsRegressor()),\n",
    "    ('MLPRegressor', sklearn.neural_network.multilayer_perceptron.MLPRegressor()),\n",
    "    ('DecisionTreeRegressor', sklearn.tree.tree.DecisionTreeRegressor()),\n",
    "    ('ExtraTreeRegressor', sklearn.tree.tree.ExtraTreeRegressor())\n",
    "]\n",
    "\n",
    "len(tecnicas_regressao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(mensagem):\n",
    "    \"\"\"\n",
    "    Função para receber uma mensagem e exibir.\n",
    "    Futuramente esta função pode receber a funcionalidade de salvar as mensagens de log em arquivo\n",
    "    \"\"\"\n",
    "    print(str(datetime.now()) + ': ' + mensagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumeroAleatorio(tipo, maximo=None):\n",
    "    \"\"\"\n",
    "    Função para retornar um número aleatório de acordo com o tipo que é passado por parâmetro.        \n",
    "    \"\"\"\n",
    "    \n",
    "    if tipo == 'cross_validation': \n",
    "        return random.randint(3,10) # Definido que a quantidade de divisão dos dados (split) será entre 3 a 10 partes (folds)\n",
    "    elif tipo == 'random_state':\n",
    "        return random.randint(1, 42) # Valor do random state poderá variar entre 1 e 42\n",
    "    elif tipo == 'simples':  # Retorna um número entre 0 e o valor passado por parâmetro\n",
    "        return random.randint(0,maximo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDados(X, y):\n",
    "    \"\"\"\n",
    "    Função para separar os dados de treino e teste, escolhendo aleatoriamente qual será a forma de separar os dados.\n",
    "    Formas disponíveis de separação:\n",
    "        - 80% para treino e 20% para teste\n",
    "        - 75% para treino e 25% para teste\n",
    "        - 70% para treino e 30% para teste\n",
    "    \"\"\"\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', 2)\n",
    "    \n",
    "    random_state = getNumeroAleatorio('random_state')\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        tipo_split = 'train_test_split 20%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    elif aleatorio == 1:\n",
    "        tipo_split = 'train_test_split 25%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state)\n",
    "    elif aleatorio == 2:\n",
    "        tipo_split = 'train_test_split 30%'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tipo_split, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizador():\n",
    "    \"\"\"\n",
    "    Retorna aleatoriamente qual normalizador será utilizado ou se não será utilizado normalizador.\n",
    "    Se algum normalizador for escolhido, é retornado a lista de parâmetros do normalizador escolhido.\n",
    "    Normalizadores disponíveis:\n",
    "        - StandardScaler\n",
    "        - RobustScaler\n",
    "        - MinMaxScaler\n",
    "        - Normalizer\n",
    "    \"\"\"\n",
    "    \n",
    "    normalizador = [(),\n",
    "                    ('standard_scaler', StandardScaler()),\n",
    "                    ('robust_scaler', RobustScaler()),\n",
    "                    ('min_max_scaler', MinMaxScaler()),\n",
    "                    ('normalizer', Normalizer())\n",
    "                   ]\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', len(normalizador)-1)\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        parametros = {}\n",
    "    elif normalizador[aleatorio][0] == 'standard_scaler':\n",
    "        parametros = {\n",
    "            'standard_scaler__with_mean': [True, False],\n",
    "            'standard_scaler__with_std': [True, False]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'robust_scaler':\n",
    "        parametros = {\n",
    "            'robust_scaler__with_centering': [True, False],\n",
    "            'robust_scaler__with_scaling': [True, False]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'min_max_scaler':\n",
    "        parametros = {\n",
    "            'min_max_scaler__feature_range': [(0,1), (1,10), (1,100)]\n",
    "        }\n",
    "    elif normalizador[aleatorio][0] == 'normalizer':\n",
    "        parametros = {\n",
    "            'normalizer__norm': ('l1', 'l2', 'max')\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return normalizador[aleatorio], parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRedutorDimensionalidade():\n",
    "    \"\"\"\n",
    "    Retorna aleatoriamente qual redutor de dimensionalidade será utilizado ou se não será utilizado redutor de dimensionalidade.\n",
    "    Se for escolhido um redutor de dimensionalidade, é retornado a lista de parâmetros do redutor de dimensionalidade escolhido.\n",
    "    Redutor de dimensionalidade disponível:\n",
    "        - PCA\n",
    "    \"\"\"    \n",
    "    \n",
    "    redutor_dimensionalidade = [(),\n",
    "                                ('pca', PCA())\n",
    "                               ]\n",
    "    \n",
    "    aleatorio = getNumeroAleatorio('simples', len(redutor_dimensionalidade)-1)\n",
    "    \n",
    "    if aleatorio == 0:\n",
    "        parametros = {}\n",
    "    elif redutor_dimensionalidade[aleatorio][0] == 'pca':\n",
    "        parametros = {\n",
    "            'pca__n_components': [None, 3, 5, 7, 9, 11],\n",
    "            'pca__whiten': [True, False],\n",
    "            'pca__svd_solver': ('auto', 'full', 'randomized')\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return redutor_dimensionalidade[aleatorio], parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParametrosTecnica(tecnica):\n",
    "    \"\"\"\n",
    "    Recebe o nome de uma técnica de predição por parâmetro, e retorna os parâmetros da técnica\n",
    "    \"\"\"\n",
    "    \n",
    "    if  tecnica == 'LinearRegression':\n",
    "        parametros = {\n",
    "            'LinearRegression__fit_intercept': [True, False],\n",
    "            'LinearRegression__normalize': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'RandomForestRegressor':\n",
    "        parametros = {\n",
    "            'RandomForestRegressor__n_estimators': [5, 10, 15],\n",
    "            'RandomForestRegressor__criterion': ('mse', 'mae'),\n",
    "            'RandomForestRegressor__max_features': ('auto', 'sqrt', 'log2'),\n",
    "            'RandomForestRegressor__bootstrap': [True, False],\n",
    "            'RandomForestRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'ExtraTreesRegressor':\n",
    "        parametros = {\n",
    "            'ExtraTreesRegressor__n_estimators': [5, 10, 15],\n",
    "            'ExtraTreesRegressor__criterion': ('mse', 'mae'),\n",
    "            'ExtraTreesRegressor__max_features': ('auto', 'sqrt', 'log2'),\n",
    "            'ExtraTreesRegressor__bootstrap': [True, False],\n",
    "            'ExtraTreesRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'BaggingRegressor':\n",
    "        parametros = {\n",
    "            'BaggingRegressor__n_estimators': [5, 10, 15],\n",
    "            'BaggingRegressor__bootstrap': [True, False],\n",
    "            'BaggingRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'GradientBoostingRegressor':\n",
    "        parametros = {\n",
    "            'GradientBoostingRegressor__loss': ('ls', 'lad', 'huber', 'quantile'),\n",
    "            'GradientBoostingRegressor__criterion': ('friedman_mse', 'mse', 'mae'),\n",
    "            'GradientBoostingRegressor__max_features': ('auto', 'sqrt', 'log2'),\n",
    "            'GradientBoostingRegressor__n_estimators': [50, 100, 150],\n",
    "            'GradientBoostingRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'AdaBoostRegressor':\n",
    "        parametros = {\n",
    "            'AdaBoostRegressor__loss': ('linear', 'square', 'exponential'),\n",
    "            'AdaBoostRegressor__n_estimators': [25, 50, 75]\n",
    "        }\n",
    "    elif tecnica == 'HuberRegressor':\n",
    "        parametros = {\n",
    "            'HuberRegressor__max_iter': [50, 100, 150],\n",
    "            'HuberRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'PassiveAggressiveRegressor':\n",
    "        parametros = {\n",
    "            'PassiveAggressiveRegressor__max_iter': [500, 1000, 1500],\n",
    "            'PassiveAggressiveRegressor__fit_intercept': [True, False],\n",
    "            'PassiveAggressiveRegressor__early_stopping': [True, False],\n",
    "            'PassiveAggressiveRegressor__shuffle': [True, False],\n",
    "            'PassiveAggressiveRegressor__warm_start': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'SGDRegressor':\n",
    "        parametros = {\n",
    "            'SGDRegressor__loss': ('squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'),\n",
    "            'SGDRegressor__penalty': ('l1', 'l2', 'elasticnet', None),\n",
    "            'SGDRegressor__max_iter': [500, 1000, 1500],\n",
    "            'SGDRegressor__shuffle': [True, False],\n",
    "            'SGDRegressor__warm_start': [True, False],\n",
    "            'SGDRegressor__learning_rate': ('constant', 'optimal', 'invscaling', 'adaptive'),\n",
    "            'SGDRegressor__early_stopping': [True, False]\n",
    "        }\n",
    "    elif tecnica == 'TheilSenRegressor':\n",
    "        parametros = {\n",
    "            'TheilSenRegressor__fit_intercept': [True, False],\n",
    "            'TheilSenRegressor__max_iter': [150, 300, 450]\n",
    "        }\n",
    "    elif tecnica == 'KNeighborsRegressor':\n",
    "        parametros = {\n",
    "            'KNeighborsRegressor__n_neighbors': [3,5,7,9],\n",
    "            'KNeighborsRegressor__weights': ('uniform', 'distance'),\n",
    "            'KNeighborsRegressor__algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "            'KNeighborsRegressor__p': [1,2]\n",
    "        }\n",
    "    elif tecnica == 'RadiusNeighborsRegressor':\n",
    "        parametros = {\n",
    "            'RadiusNeighborsRegressor__weights': ('uniform', 'distance'),\n",
    "            'RadiusNeighborsRegressor__algorithm': ('ball_tree', 'kd_tree', 'brute', 'auto'),\n",
    "            'RadiusNeighborsRegressor__p': [1, 2]\n",
    "        }\n",
    "    elif tecnica == 'MLPRegressor':\n",
    "        parametros = {\n",
    "            'MLPRegressor__hidden_layer_sizes': [(1,), (100,), (500,), (1,3), (100,3), (500,3)],\n",
    "            'MLPRegressor__activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "            'MLPRegressor__solver': ('lbfgs', 'sgd', 'adam'),\n",
    "            'MLPRegressor__learning_rate': ('constant', 'invscaling', 'adaptive'),\n",
    "            'MLPRegressor__shuffle': [True, False],\n",
    "            'MLPRegressor__max_iter': [100, 200, 300, 1000],\n",
    "            'MLPRegressor__tol': [0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    elif tecnica == 'DecisionTreeRegressor':\n",
    "        parametros = {\n",
    "            'DecisionTreeRegressor__criterion': ('gini', 'entropy'),\n",
    "            'DecisionTreeRegressor__splitter': ('best', 'random'),\n",
    "            'DecisionTreeRegressor__max_features': ('auto', 'sqrt', 'log2'),\n",
    "        }\n",
    "    elif tecnica == 'ExtraTreeRegressor':\n",
    "        parametros = {\n",
    "            'ExtraTreeRegressor__criterion': ('mse', 'mae'),\n",
    "            'ExtraTreeRegressor__max_features': ('auto', 'sqrt', 'log2')\n",
    "        }\n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratarPredict(predict):\n",
    "    \"\"\"\n",
    "    Função para tratar os valores preditos.\n",
    "    É necessário tratar os valores preditos pelos seguintes motivos:\n",
    "        - O atributo classe 'quality' é do tipo inteiro e deve conter valores entre 0 e 10\n",
    "        - Uma técnica de regressão pode predizer valores que não são inteiros. Exemplo: 4.27\n",
    "        - Uma técnica de regressão pode predizer valores abaixo de 0 (valores negativos) e valores acima de 10\n",
    "        \n",
    "    Tratamentos realizados:\n",
    "        - Arredondar valor para número inteiro\n",
    "        - Se o valor for menor que 0, atribuir o valor de 0\n",
    "        - Se o valor for maior que 10, atribuir o valor de 10\n",
    "    \"\"\"\n",
    "    \n",
    "    predict = predict.round()\n",
    "    predict = predict.astype('int')\n",
    "    \n",
    "    predict[predict < 0] = 0\n",
    "    \n",
    "    predict[predict > 10] = 10\n",
    "    \n",
    "    return predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvarDesempenho(resultados):\n",
    "    \"\"\"\n",
    "    Função que recebe um Pandas DataFrame por parâmetro, e salva os dados no arquivo CSV.\n",
    "    Caso já exista um arquivo, os dados recebidos por parâmetro são adicionados no arquivo\n",
    "    \"\"\"\n",
    "    \n",
    "    nome_arquivo = 'resultados_treino.csv'    \n",
    "    \n",
    "    try:\n",
    "        csv_resultados = pd.read_csv(nome_arquivo, sep=';') # Abrir arquivo existente\n",
    "        csv_resultados = pd.concat([csv_resultados, resultados]) # Adicionar dados recebidos por parâmetro ao conjunto de dados já existente\n",
    "        csv_resultados.to_csv(nome_arquivo, sep=';', index=False) # Salvar os dados \n",
    "    except FileNotFoundError: # Caso não exista o arquivo, será criado um novo com os dados recebido por parâmetro\n",
    "        resultados.to_csv(nome_arquivo, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliarDesempenho(tecnica, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Função que recebe o valor verdadeiro/real (y_true) e o valor predito (y_pred), \n",
    "    aplica os avaliadores de desempenho e retorna o resultado dos avaliadores de desempenho.\n",
    "    Avaliadores de desempenho aplicados:\n",
    "        - mean_absolute_error\n",
    "        - mean_squared_error\n",
    "        - mean_squared_log_error\n",
    "        - median_absolute_error\n",
    "    \"\"\"\n",
    "    \n",
    "    resultados = {}\n",
    "    resultados['tecnica'] = [tecnica]\n",
    "    # Aplicando avaliadores de desempenho        \n",
    "    resultados['mean_absolute_error'] = [sklearn.metrics.mean_absolute_error(y_true, y_pred)]\n",
    "    resultados['mean_squared_error'] = [sklearn.metrics.mean_squared_error(y_true, y_pred)]\n",
    "    resultados['mean_squared_log_error'] = [sklearn.metrics.mean_squared_log_error(y_true, y_pred)]\n",
    "    resultados['median_absolute_error'] = [sklearn.metrics.median_absolute_error(y_true, y_pred)]\n",
    "        \n",
    "    log('Técnica: {0} - mean_absolute_error: {1}, mean_squared_error: {2}, mean_squared_log_error: {3}, median_absolute_error: {4}'.format(\n",
    "            tecnica, resultados['mean_absolute_error'], resultados['mean_squared_error'], resultados['mean_squared_log_error'], resultados['median_absolute_error']) )\n",
    "    \n",
    "    pd_resultados = pd.DataFrame(data=resultados)   \n",
    "    \n",
    "    return pd_resultados    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoModeling(X, y, quantidade_execucoes):\n",
    "    \"\"\"\n",
    "    Função que executa todas as etapas necessárias para separar os dados em treino e teste, e montar o pipeline de treinamento\n",
    "    O pipeline é composto de:\n",
    "        - Normalizador e seus parâmetros, se existente\n",
    "        - Redutor de dimensionalidade e seus parâmetros, se existente\n",
    "        - Técnica de predição e seus parâmetros\n",
    "    Após o pipeline estar montado, é realizado uma busca aleatória (Random Search) para encontrar a melhor combinação de parâmetros, essa busca aleatória é executada por 4 vezes\n",
    "    Após feito a busca aleatória pela melhor combinação de parâmetros, é realizado a predição do 'X_test', para posteriormente aplicar a avaliação de desempenho do modelo de predição\n",
    "    Aplicado a avaliação de desempenho, seus resultados são salvos em um arquivo .csv\n",
    "    Posteriomente, o modelo gerado é salvo (.pkl)\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(1,quantidade_execucoes+1):\n",
    "    \n",
    "        log('========== Iniciando execução número: ' + str(i))\n",
    "\n",
    "        X_train, X_test, y_train, y_test, tipo_split, random_state_split = splitDados(X, y) # Separando os dados em treino e teste\n",
    "\n",
    "\n",
    "        pipeline = []\n",
    "        parametros = {}\n",
    "\n",
    "        normalizador_pipeline, normalizador_parametros = getNormalizador() # Coletando o normalizador, que será definido aleatoriamente\n",
    "        normalizador_nome = 'Não utilizado'\n",
    "        if len(normalizador_pipeline) > 0: # Se for definido que terá normalizador, o normalizador é adicionado no pipeline e no array que salva os parâmetros\n",
    "            pipeline += [normalizador_pipeline]\n",
    "            parametros.update(normalizador_parametros)\n",
    "            normalizador_nome = normalizador_pipeline[0]\n",
    "\n",
    "        redutor_dimensionalidade_pipeline, redutor_dimensionalidade_parametros = getRedutorDimensionalidade() # Coletando o redutor de dimensionalidade, que será definido aleatoriamente\n",
    "        redutor_dimensionalidade_nome = 'Não utilizado'\n",
    "        if len(redutor_dimensionalidade_pipeline) > 0: # Se for definido que terá redutor de dimensionalidade, o redutor de dimensionalidade é adicionado no pipeline e no array que salva os parâmetros\n",
    "            pipeline += [redutor_dimensionalidade_pipeline]\n",
    "            parametros.update(redutor_dimensionalidade_parametros)\n",
    "            redutor_dimensionalidade_nome = redutor_dimensionalidade_pipeline[0]\n",
    "\n",
    "\n",
    "        log('========== Iniciando treinamento com normalizador: {0}, redutor_dimensionalidade: {1}'.format(normalizador_nome, redutor_dimensionalidade_nome))\n",
    "        \n",
    "\n",
    "        for tecnica, model in tecnicas_regressao: # Para cada técnica presente na variável \"tecnicas_regressao\", coletar os parametros da técnica, realizar o random search e avaliar o seu desempenho\n",
    "            log('Técnica: ' + tecnica)\n",
    "            try:\n",
    "\n",
    "                pipeline_tecnica = pipeline.copy()\n",
    "                pipeline_tecnica += [(tecnica, model)] # Adicionando a técnica no pipeline\n",
    "\n",
    "                parametros_tecnica = parametros.copy()\n",
    "                parametros_tecnica.update(getParametrosTecnica(tecnica)) # Coletando os parâmetros da técnica e adicionando no array de parâmetros\n",
    "\n",
    "                pipeline_final = Pipeline(pipeline_tecnica)\n",
    "\n",
    "                cross_validation = getNumeroAleatorio('cross_validation') # Coletando um número aleatório para representar o cross_validation do Random Search\n",
    "                random_state = getNumeroAleatorio('random_state') # Coletando um número aleatório para representar o random_state do Random Search\n",
    "\n",
    "                # Executando o Random Search com 4 iterações\n",
    "                modelo = RandomizedSearchCV(n_iter=4, estimator=pipeline_final, param_distributions=parametros_tecnica, cv=cross_validation, random_state=random_state, n_jobs= -1)\n",
    "\n",
    "                modelo.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = modelo.predict(X_test) # Realizando a predição para os dados de teste\n",
    "\n",
    "                y_pred = tratarPredict(y_pred) # Tratar os valores preditos\n",
    "                \n",
    "                desempenho_tecnica = avaliarDesempenho(tecnica=tecnica, y_true=y_test, y_pred=y_pred) # Chamando a função que avalia o desempenho da técnica\n",
    "\n",
    "                # Adicionando informações relevantes e informações para identificar como é o modelo gerado, permitindo que seja reproduzido manualmente caso necessário\n",
    "                identificador_aleatorio = getNumeroAleatorio('simples', 9999999) # Gerar um identificador aleatório para o resultado dessa técnica\n",
    "                desempenho_tecnica['identificador_aleatorio'] = [identificador_aleatorio]\n",
    "                desempenho_tecnica['tipo_split'] = [tipo_split]\n",
    "                desempenho_tecnica['normalizador'] = [normalizador_nome]\n",
    "                desempenho_tecnica['redutor_dimensionalidade'] = [redutor_dimensionalidade_nome]\n",
    "                desempenho_tecnica['pipeline'] = [str(pipeline_tecnica)]\n",
    "                desempenho_tecnica['parametros'] = [str(parametros_tecnica)]\n",
    "                desempenho_tecnica['random_state_split'] = [random_state_split]\n",
    "                desempenho_tecnica['random_state_random_search'] = [random_state]\n",
    "                desempenho_tecnica['cross_validation_random_search'] = [cross_validation]\n",
    "                desempenho_tecnica['best_estimator'] = [modelo.best_estimator_]\n",
    "                desempenho_tecnica['best_params'] = [modelo.best_params_]\n",
    "\n",
    "                salvarDesempenho(desempenho_tecnica) # Salvando o desempenho da técnica\n",
    "\n",
    "\n",
    "\n",
    "                nome_arquivo = 'modelos/' + str(identificador_aleatorio) + '_' + tecnica + '.pkl' # Criando o nome do arquivo, ex.: 112302_KNeighborsRegressor.pkl\n",
    "                joblib.dump(modelo.best_estimator_, nome_arquivo) # Salvando o modelo\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                log('Erro durante execução da técnica: ' + tecnica)\n",
    "                #print(e)\n",
    "                pass # Passar para a próxima técnica\n",
    "\n",
    "\n",
    "\n",
    "            del(pipeline_tecnica) # Liberar memória\n",
    "            del(parametros_tecnica) # Liberar memória\n",
    "\n",
    "        log('========== Finalizado execução número: ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao total foram feitas 20 execuções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-01 16:35:52.103518: ========== Iniciando execução número: 1\n",
      "2019-09-01 16:35:52.107515: ========== Iniciando treinamento com normalizador: Não utilizado, redutor_dimensionalidade: Não utilizado\n",
      "2019-09-01 16:35:52.107515: Técnica: RandomForestRegressor\n",
      "2019-09-01 16:36:15.597991: Técnica: RandomForestRegressor - mean_absolute_error: [0.4270967741935484], mean_squared_error: [0.5225806451612903], mean_squared_log_error: [0.011916322705044688], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:15.650959: Técnica: ExtraTreesRegressor\n",
      "2019-09-01 16:36:44.693914: Técnica: ExtraTreesRegressor - mean_absolute_error: [0.42516129032258065], mean_squared_error: [0.5051612903225806], mean_squared_log_error: [0.011606029125889957], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:44.752876: Técnica: BaggingRegressor\n",
      "2019-09-01 16:36:46.038078: Técnica: BaggingRegressor - mean_absolute_error: [0.41935483870967744], mean_squared_error: [0.4993548387096774], mean_squared_log_error: [0.01125488861488751], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:46.095048: Técnica: GradientBoostingRegressor\n",
      "2019-09-01 16:36:47.575191: Técnica: GradientBoostingRegressor - mean_absolute_error: [0.46], mean_squared_error: [0.532258064516129], mean_squared_log_error: [0.011976079542075736], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:47.632157: Técnica: AdaBoostRegressor\n",
      "2019-09-01 16:36:50.284950: Técnica: AdaBoostRegressor - mean_absolute_error: [0.5309677419354839], mean_squared_error: [0.6406451612903226], mean_squared_log_error: [0.01423381741141735], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:50.358701: Técnica: HuberRegressor\n",
      "2019-09-01 16:36:50.907249: Técnica: HuberRegressor - mean_absolute_error: [0.5251612903225806], mean_squared_error: [0.6606451612903226], mean_squared_log_error: [0.014676386965354657], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:50.956723: Técnica: LinearRegression\n",
      "2019-09-01 16:36:51.050664: Técnica: LinearRegression - mean_absolute_error: [0.5161290322580645], mean_squared_error: [0.6296774193548387], mean_squared_log_error: [0.014050129092533316], median_absolute_error: [0.0]\n",
      "2019-09-01 16:36:51.096636: Técnica: PassiveAggressiveRegressor\n",
      "2019-09-01 16:36:51.297512: Técnica: PassiveAggressiveRegressor - mean_absolute_error: [0.9761290322580645], mean_squared_error: [1.6380645161290324], mean_squared_log_error: [0.03340963899705749], median_absolute_error: [1.0]\n",
      "2019-09-01 16:36:51.347480: Técnica: SGDRegressor\n",
      "2019-09-01 16:36:52.274478: Técnica: SGDRegressor - mean_absolute_error: [0.9716129032258064], mean_squared_error: [1.5935483870967742], mean_squared_log_error: [0.03294206736917084], median_absolute_error: [1.0]\n",
      "2019-09-01 16:36:52.323448: Técnica: TheilSenRegressor\n",
      "2019-09-01 16:37:01.328132: Técnica: TheilSenRegressor - mean_absolute_error: [0.6316129032258064], mean_squared_error: [1.3374193548387097], mean_squared_log_error: [0.09395693121637791], median_absolute_error: [0.0]\n",
      "2019-09-01 16:37:01.377605: Técnica: KNeighborsRegressor\n",
      "2019-09-01 16:37:01.838321: Técnica: KNeighborsRegressor - mean_absolute_error: [0.5051612903225806], mean_squared_error: [0.6496774193548387], mean_squared_log_error: [0.0147006126418538], median_absolute_error: [0.0]\n",
      "2019-09-01 16:37:01.892304: Técnica: RadiusNeighborsRegressor\n",
      "2019-09-01 16:37:02.200238: Técnica: RadiusNeighborsRegressor - mean_absolute_error: [4.409032258064516], mean_squared_error: [25.923870967741937], mean_squared_log_error: [2.7715030474383693], median_absolute_error: [5.0]\n",
      "2019-09-01 16:37:02.248208: Técnica: MLPRegressor\n",
      "2019-09-01 16:37:19.978746: Técnica: MLPRegressor - mean_absolute_error: [0.5361290322580645], mean_squared_error: [0.6767741935483871], mean_squared_log_error: [0.01512086285982949], median_absolute_error: [0.0]\n",
      "2019-09-01 16:37:20.040707: Técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:37:20.182620: Erro durante execução da técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:37:20.183620: Técnica: ExtraTreeRegressor\n",
      "2019-09-01 16:37:24.737627: Técnica: ExtraTreeRegressor - mean_absolute_error: [0.5754838709677419], mean_squared_error: [0.832258064516129], mean_squared_log_error: [0.01883591570214186], median_absolute_error: [0.0]\n",
      "2019-09-01 16:37:24.787596: ========== Finalizado execução número: 1\n",
      "2019-09-01 16:37:24.787596: ========== Iniciando execução número: 2\n",
      "2019-09-01 16:37:24.790594: ========== Iniciando treinamento com normalizador: min_max_scaler, redutor_dimensionalidade: pca\n",
      "2019-09-01 16:37:24.790594: Técnica: RandomForestRegressor\n",
      "2019-09-01 16:41:39.388296: Técnica: RandomForestRegressor - mean_absolute_error: [0.42492260061919507], mean_squared_error: [0.5379256965944272], mean_squared_log_error: [0.0127650799380311], median_absolute_error: [0.0]\n",
      "2019-09-01 16:41:39.445261: Técnica: ExtraTreesRegressor\n",
      "2019-09-01 16:41:45.666403: Técnica: ExtraTreesRegressor - mean_absolute_error: [0.39473684210526316], mean_squared_error: [0.5077399380804953], mean_squared_log_error: [0.012171600693801809], median_absolute_error: [0.0]\n",
      "2019-09-01 16:41:45.731363: Técnica: BaggingRegressor\n",
      "2019-09-01 16:41:46.648794: Técnica: BaggingRegressor - mean_absolute_error: [0.4605263157894737], mean_squared_error: [0.596749226006192], mean_squared_log_error: [0.014116893931028432], median_absolute_error: [0.0]\n",
      "2019-09-01 16:41:46.715754: Técnica: GradientBoostingRegressor\n",
      "2019-09-01 16:43:28.376591: Técnica: GradientBoostingRegressor - mean_absolute_error: [0.5464396284829721], mean_squared_error: [0.6749226006191951], mean_squared_log_error: [0.01562755549961817], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:28.439552: Técnica: AdaBoostRegressor\n",
      "2019-09-01 16:43:34.315816: Técnica: AdaBoostRegressor - mean_absolute_error: [0.5456656346749226], mean_squared_error: [0.6679566563467493], mean_squared_log_error: [0.015402600523184538], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:34.408758: Técnica: HuberRegressor\n",
      "2019-09-01 16:43:34.790028: Técnica: HuberRegressor - mean_absolute_error: [0.5348297213622291], mean_squared_error: [0.6756965944272446], mean_squared_log_error: [0.015504230399730486], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:34.842995: Técnica: LinearRegression\n",
      "2019-09-01 16:43:34.986907: Técnica: LinearRegression - mean_absolute_error: [0.5534055727554179], mean_squared_error: [0.7020123839009288], mean_squared_log_error: [0.01613262889111253], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:35.038873: Técnica: PassiveAggressiveRegressor\n",
      "2019-09-01 16:43:35.385659: Técnica: PassiveAggressiveRegressor - mean_absolute_error: [5.178018575851393], mean_squared_error: [27.648606811145513], mean_squared_log_error: [2.5284765448275004], median_absolute_error: [5.0]\n",
      "2019-09-01 16:43:35.440624: Técnica: SGDRegressor\n",
      "2019-09-01 16:43:35.816392: Técnica: SGDRegressor - mean_absolute_error: [0.5565015479876161], mean_squared_error: [0.708204334365325], mean_squared_log_error: [0.016329483372703884], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:35.868360: Técnica: TheilSenRegressor\n",
      "2019-09-01 16:43:54.916370: Técnica: TheilSenRegressor - mean_absolute_error: [0.5518575851393189], mean_squared_error: [0.7205882352941176], mean_squared_log_error: [0.016234845791601924], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:54.975333: Técnica: KNeighborsRegressor\n",
      "2019-09-01 16:43:55.380499: Técnica: KNeighborsRegressor - mean_absolute_error: [0.4481424148606811], mean_squared_error: [0.5828173374613003], mean_squared_log_error: [0.013849536433201935], median_absolute_error: [0.0]\n",
      "2019-09-01 16:43:55.437463: Técnica: RadiusNeighborsRegressor\n",
      "2019-09-01 16:43:56.137063: Técnica: RadiusNeighborsRegressor - mean_absolute_error: [0.6563467492260062], mean_squared_error: [0.8359133126934984], mean_squared_log_error: [0.01949211014307766], median_absolute_error: [1.0]\n",
      "2019-09-01 16:43:56.191030: Técnica: MLPRegressor\n",
      "2019-09-01 16:44:06.568907: Técnica: MLPRegressor - mean_absolute_error: [0.5030959752321982], mean_squared_error: [0.6191950464396285], mean_squared_log_error: [0.01436446119079434], median_absolute_error: [0.0]\n",
      "2019-09-01 16:44:06.634902: Técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:44:06.779890: Erro durante execução da técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:44:06.779890: Técnica: ExtraTreeRegressor\n",
      "2019-09-01 16:44:10.785248: Técnica: ExtraTreeRegressor - mean_absolute_error: [0.5247678018575851], mean_squared_error: [0.7631578947368421], mean_squared_log_error: [0.01767154498554823], median_absolute_error: [0.0]\n",
      "2019-09-01 16:44:10.838215: ========== Finalizado execução número: 2\n",
      "2019-09-01 16:44:10.838215: ========== Iniciando execução número: 3\n",
      "2019-09-01 16:44:10.840213: ========== Iniciando treinamento com normalizador: robust_scaler, redutor_dimensionalidade: pca\n",
      "2019-09-01 16:44:10.840213: Técnica: RandomForestRegressor\n",
      "2019-09-01 16:51:53.753873: Técnica: RandomForestRegressor - mean_absolute_error: [0.4317521781219748], mean_squared_error: [0.5150048402710552], mean_squared_log_error: [0.011677190297144383], median_absolute_error: [0.0]\n",
      "2019-09-01 16:51:53.815835: Técnica: ExtraTreesRegressor\n",
      "2019-09-01 16:51:55.718500: Técnica: ExtraTreesRegressor - mean_absolute_error: [0.42884801548886736], mean_squared_error: [0.5411423039690223], mean_squared_log_error: [0.012317703270797717], median_absolute_error: [0.0]\n",
      "2019-09-01 16:51:55.782460: Técnica: BaggingRegressor\n",
      "2019-09-01 16:51:59.493745: Técnica: BaggingRegressor - mean_absolute_error: [0.409486931268151], mean_squared_error: [0.49661181026137463], mean_squared_log_error: [0.011293293745503374], median_absolute_error: [0.0]\n",
      "2019-09-01 16:51:59.564701: Técnica: GradientBoostingRegressor\n",
      "2019-09-01 16:53:45.305050: Erro durante execução da técnica: GradientBoostingRegressor\n",
      "2019-09-01 16:53:45.306048: Técnica: AdaBoostRegressor\n",
      "2019-09-01 16:53:49.426817: Técnica: AdaBoostRegressor - mean_absolute_error: [0.5469506292352372], mean_squared_error: [0.6573088092933205], mean_squared_log_error: [0.014605159043211273], median_absolute_error: [0.0]\n",
      "2019-09-01 16:53:49.511762: Técnica: HuberRegressor\n",
      "2019-09-01 16:53:49.922698: Técnica: HuberRegressor - mean_absolute_error: [0.5382381413359149], mean_squared_error: [0.6815101645692159], mean_squared_log_error: [0.015118797507206449], median_absolute_error: [0.0]\n",
      "2019-09-01 16:53:49.975170: Técnica: LinearRegression\n",
      "2019-09-01 16:53:50.227014: Técnica: LinearRegression - mean_absolute_error: [0.5256534365924492], mean_squared_error: [0.6515004840271055], mean_squared_log_error: [0.014470034086418754], median_absolute_error: [0.0]\n",
      "2019-09-01 16:53:50.277982: Técnica: PassiveAggressiveRegressor\n",
      "2019-09-01 16:53:50.552812: Técnica: PassiveAggressiveRegressor - mean_absolute_error: [0.8896418199419167], mean_squared_error: [1.4607938044530493], mean_squared_log_error: [0.03260360662384368], median_absolute_error: [1.0]\n",
      "2019-09-01 16:53:50.605779: Técnica: SGDRegressor\n",
      "2019-09-01 16:53:51.555694: Técnica: SGDRegressor - mean_absolute_error: [0.5953533397870281], mean_squared_error: [0.7831558567279767], mean_squared_log_error: [0.01728871505959353], median_absolute_error: [1.0]\n",
      "2019-09-01 16:53:51.609660: Técnica: TheilSenRegressor\n",
      "2019-09-01 16:54:18.309865: Técnica: TheilSenRegressor - mean_absolute_error: [0.6495643756050339], mean_squared_error: [1.0135527589545015], mean_squared_log_error: [0.04221751382851832], median_absolute_error: [1.0]\n",
      "2019-09-01 16:54:18.363831: Técnica: KNeighborsRegressor\n",
      "2019-09-01 16:54:18.760585: Técnica: KNeighborsRegressor - mean_absolute_error: [0.46950629235237173], mean_squared_error: [0.6224588576960309], mean_squared_log_error: [0.013826052982456066], median_absolute_error: [0.0]\n",
      "2019-09-01 16:54:18.820549: Técnica: RadiusNeighborsRegressor\n",
      "2019-09-01 16:54:19.608585: Técnica: RadiusNeighborsRegressor - mean_absolute_error: [0.4888673765730881], mean_squared_error: [0.6534365924491772], mean_squared_log_error: [0.01787722350201368], median_absolute_error: [0.0]\n",
      "2019-09-01 16:54:19.662552: Técnica: MLPRegressor\n",
      "2019-09-01 16:54:28.649135: Técnica: MLPRegressor - mean_absolute_error: [0.5624394966118103], mean_squared_error: [0.7153920619554696], mean_squared_log_error: [0.01575243498915255], median_absolute_error: [0.0]\n",
      "2019-09-01 16:54:28.710097: Técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:54:28.880991: Erro durante execução da técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:54:28.880991: Técnica: ExtraTreeRegressor\n",
      "2019-09-01 16:54:31.713570: Técnica: ExtraTreeRegressor - mean_absolute_error: [0.5663117134559535], mean_squared_error: [0.8528557599225557], mean_squared_log_error: [0.01876038394968758], median_absolute_error: [0.0]\n",
      "2019-09-01 16:54:31.767537: ========== Finalizado execução número: 3\n",
      "2019-09-01 16:54:31.767537: ========== Iniciando execução número: 4\n",
      "2019-09-01 16:54:31.769535: ========== Iniciando treinamento com normalizador: robust_scaler, redutor_dimensionalidade: Não utilizado\n",
      "2019-09-01 16:54:31.770534: Técnica: RandomForestRegressor\n",
      "2019-09-01 16:55:21.279032: Técnica: RandomForestRegressor - mean_absolute_error: [0.45278637770897834], mean_squared_error: [0.5735294117647058], mean_squared_log_error: [0.01312645810961943], median_absolute_error: [0.0]\n",
      "2019-09-01 16:55:21.336996: Técnica: ExtraTreesRegressor\n",
      "2019-09-01 16:55:29.978793: Técnica: ExtraTreesRegressor - mean_absolute_error: [0.4102167182662539], mean_squared_error: [0.5061919504643962], mean_squared_log_error: [0.011687557634412012], median_absolute_error: [0.0]\n",
      "2019-09-01 16:55:30.039755: Técnica: BaggingRegressor\n",
      "2019-09-01 16:55:31.317495: Técnica: BaggingRegressor - mean_absolute_error: [0.40634674922600617], mean_squared_error: [0.48993808049535603], mean_squared_log_error: [0.011348187987194756], median_absolute_error: [0.0]\n",
      "2019-09-01 16:55:31.376457: Técnica: GradientBoostingRegressor\n",
      "2019-09-01 16:56:14.727570: Técnica: GradientBoostingRegressor - mean_absolute_error: [0.5247678018575851], mean_squared_error: [0.6501547987616099], mean_squared_log_error: [0.014527371926798285], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:14.790536: Técnica: AdaBoostRegressor\n",
      "2019-09-01 16:56:18.186739: Técnica: AdaBoostRegressor - mean_absolute_error: [0.5526315789473685], mean_squared_error: [0.6811145510835913], mean_squared_log_error: [0.01530919838841227], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:18.257695: Técnica: HuberRegressor\n",
      "2019-09-01 16:56:19.145933: Técnica: HuberRegressor - mean_absolute_error: [0.5294117647058824], mean_squared_error: [0.6888544891640866], mean_squared_log_error: [0.015587501847708329], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:19.198900: Técnica: LinearRegression\n",
      "2019-09-01 16:56:19.286845: Técnica: LinearRegression - mean_absolute_error: [0.5340557275541795], mean_squared_error: [0.6625386996904025], mean_squared_log_error: [0.014978253258561197], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:19.341811: Técnica: PassiveAggressiveRegressor\n",
      "2019-09-01 16:56:19.844500: Técnica: PassiveAggressiveRegressor - mean_absolute_error: [1.088235294117647], mean_squared_error: [1.9860681114551084], mean_squared_log_error: [0.03991004974390982], median_absolute_error: [1.0]\n",
      "2019-09-01 16:56:19.899465: Técnica: SGDRegressor\n",
      "2019-09-01 16:56:20.327201: Técnica: SGDRegressor - mean_absolute_error: [5.788699690402477], mean_squared_error: [34.31037151702786], mean_squared_log_error: [3.6433708313472954], median_absolute_error: [6.0]\n",
      "2019-09-01 16:56:20.381167: Técnica: TheilSenRegressor\n",
      "2019-09-01 16:56:49.441079: Técnica: TheilSenRegressor - mean_absolute_error: [0.6462848297213623], mean_squared_error: [1.339783281733746], mean_squared_log_error: [0.09135519767820341], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:49.494046: Técnica: KNeighborsRegressor\n",
      "2019-09-01 16:56:50.031712: Técnica: KNeighborsRegressor - mean_absolute_error: [0.42724458204334365], mean_squared_error: [0.5371517027863777], mean_squared_log_error: [0.012442239116801156], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:50.084680: Técnica: RadiusNeighborsRegressor\n",
      "2019-09-01 16:56:51.099834: Técnica: RadiusNeighborsRegressor - mean_absolute_error: [1.3003095975232197], mean_squared_error: [5.975232198142415], mean_squared_log_error: [0.6122640108280253], median_absolute_error: [0.0]\n",
      "2019-09-01 16:56:51.153800: Técnica: MLPRegressor\n",
      "2019-09-01 16:56:57.814110: Técnica: MLPRegressor - mean_absolute_error: [0.6501547987616099], mean_squared_error: [0.8328173374613003], mean_squared_log_error: [0.019066965127560283], median_absolute_error: [1.0]\n",
      "2019-09-01 16:56:57.868077: Técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:56:58.015985: Erro durante execução da técnica: DecisionTreeRegressor\n",
      "2019-09-01 16:56:58.015985: Técnica: ExtraTreeRegressor\n",
      "2019-09-01 16:57:02.338895: Técnica: ExtraTreeRegressor - mean_absolute_error: [0.5580495356037152], mean_squared_error: [0.8351393188854489], mean_squared_log_error: [0.018577222307787147], median_absolute_error: [0.0]\n",
      "2019-09-01 16:57:02.391860: ========== Finalizado execução número: 4\n",
      "2019-09-01 16:57:02.391860: ========== Iniciando execução número: 5\n",
      "2019-09-01 16:57:02.394775: ========== Iniciando treinamento com normalizador: robust_scaler, redutor_dimensionalidade: pca\n",
      "2019-09-01 16:57:02.394775: Técnica: RandomForestRegressor\n",
      "2019-09-01 17:00:56.374231: Técnica: RandomForestRegressor - mean_absolute_error: [0.44451612903225807], mean_squared_error: [0.5425806451612903], mean_squared_log_error: [0.012542381978493219], median_absolute_error: [0.0]\n",
      "2019-09-01 17:00:56.440191: Técnica: ExtraTreesRegressor\n",
      "2019-09-01 17:00:58.476695: Técnica: ExtraTreesRegressor - mean_absolute_error: [0.4612903225806452], mean_squared_error: [0.5812903225806452], mean_squared_log_error: [0.013583825780243381], median_absolute_error: [0.0]\n",
      "2019-09-01 17:00:58.536660: Técnica: BaggingRegressor\n",
      "2019-09-01 17:01:01.635290: Técnica: BaggingRegressor - mean_absolute_error: [0.587741935483871], mean_squared_error: [0.8625806451612903], mean_squared_log_error: [0.019988041354821524], median_absolute_error: [0.0]\n",
      "2019-09-01 17:01:01.696251: Técnica: GradientBoostingRegressor\n",
      "2019-09-01 17:03:27.681432: Técnica: GradientBoostingRegressor - mean_absolute_error: [0.5961290322580645], mean_squared_error: [0.7625806451612903], mean_squared_log_error: [0.017441893264281826], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:27.745392: Técnica: AdaBoostRegressor\n",
      "2019-09-01 17:03:30.040585: Técnica: AdaBoostRegressor - mean_absolute_error: [0.6258064516129033], mean_squared_error: [0.7690322580645161], mean_squared_log_error: [0.017747414973379835], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:30.134526: Técnica: HuberRegressor\n",
      "2019-09-01 17:03:30.523791: Técnica: HuberRegressor - mean_absolute_error: [0.5374193548387097], mean_squared_error: [0.692258064516129], mean_squared_log_error: [0.015711345789043665], median_absolute_error: [0.0]\n",
      "2019-09-01 17:03:30.580756: Técnica: LinearRegression\n",
      "2019-09-01 17:03:30.736660: Técnica: LinearRegression - mean_absolute_error: [0.6509677419354839], mean_squared_error: [0.8225806451612904], mean_squared_log_error: [0.018788142768830094], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:30.792624: Técnica: PassiveAggressiveRegressor\n",
      "2019-09-01 17:03:31.168392: Técnica: PassiveAggressiveRegressor - mean_absolute_error: [0.7683870967741936], mean_squared_error: [1.1464516129032258], mean_squared_log_error: [0.025531972791865958], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:31.224357: Técnica: SGDRegressor\n",
      "2019-09-01 17:03:31.566144: Técnica: SGDRegressor - mean_absolute_error: [0.6006451612903225], mean_squared_error: [0.7490322580645161], mean_squared_log_error: [0.017066378648078855], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:31.621110: Técnica: TheilSenRegressor\n",
      "2019-09-01 17:03:47.726939: Técnica: TheilSenRegressor - mean_absolute_error: [0.7032258064516129], mean_squared_error: [1.304516129032258], mean_squared_log_error: [0.025378503210138095], median_absolute_error: [1.0]\n",
      "2019-09-01 17:03:47.782904: Técnica: KNeighborsRegressor\n",
      "2019-09-01 17:03:48.314590: Técnica: KNeighborsRegressor - mean_absolute_error: [0.5187096774193548], mean_squared_error: [0.655483870967742], mean_squared_log_error: [0.015059701795514219], median_absolute_error: [0.0]\n",
      "2019-09-01 17:03:48.371589: Técnica: RadiusNeighborsRegressor\n",
      "2019-09-01 17:03:49.164947: Técnica: RadiusNeighborsRegressor - mean_absolute_error: [0.5367741935483871], mean_squared_error: [0.7135483870967742], mean_squared_log_error: [0.01986481990549195], median_absolute_error: [0.0]\n",
      "2019-09-01 17:03:49.222911: Técnica: MLPRegressor\n",
      "2019-09-01 17:05:22.265576: Técnica: MLPRegressor - mean_absolute_error: [0.5393548387096774], mean_squared_error: [0.6670967741935484], mean_squared_log_error: [0.015202070560233106], median_absolute_error: [0.0]\n",
      "2019-09-01 17:05:22.325540: Técnica: DecisionTreeRegressor\n",
      "2019-09-01 17:05:22.487953: Erro durante execução da técnica: DecisionTreeRegressor\n",
      "2019-09-01 17:05:22.488953: Técnica: ExtraTreeRegressor\n",
      "2019-09-01 17:05:27.524887: Técnica: ExtraTreeRegressor - mean_absolute_error: [0.5787096774193549], mean_squared_error: [0.8470967741935483], mean_squared_log_error: [0.019591401353830456], median_absolute_error: [0.0]\n",
      "2019-09-01 17:05:27.581851: ========== Finalizado execução número: 5\n"
     ]
    }
   ],
   "source": [
    "# Executando por 5 vezes o treinamento das técnicas com os dados de treino (X e y) \n",
    "autoModeling(X, y, quantidade_execucoes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "# Próxima etapa: \"Evaluation\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
